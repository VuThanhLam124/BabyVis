# BabyVis - GGUF Edition# ğŸ¤– BabyVis - Qwen Edition# BabyVis â€” Táº¡o áº£nh em bÃ© tá»« áº£nh siÃªu Ã¢m



ğŸ¤– **AI-powered ultrasound to baby face visualization using Qwen Image Edit GGUF model**



## ğŸš€ Quick Start**Dá»± Ä‘oÃ¡n hÃ¬nh áº£nh em bÃ© tá»« siÃªu Ã¢m sá»­ dá»¥ng Qwen Image Edit AI**BabyVis lÃ  má»™t cÃ´ng cá»¥ táº¡o áº£nh em bÃ© tá»« áº£nh siÃªu Ã¢m dá»±a trÃªn Stable Diffusion + ControlNet (Canny), kÃ¨m giao diá»‡n Gradio thÃ¢n thiá»‡n vÃ  cháº¿ Ä‘á»™ xá»­ lÃ½ theo lÃ´.



### Option 1: GPU 4GB VRAM

```bash

./run_4gb.sh[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://python.org)## CÃ i Ä‘áº·t

```

[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)- YÃªu cáº§u Python 3.9+

### Option 2: GPU 12GB VRAM  

```bash- CÃ i thÆ° viá»‡n:

./run_12gb.sh

```## ğŸš€ TÃ­nh nÄƒng  - `pip install -r requirements.txt`



### Option 3: CPU Only

```bash

./run_cpu.sh- **ğŸ§  Pure Qwen AI**: Sá»­ dá»¥ng hoÃ n toÃ n Qwen Image Edit - loáº¡i bá» ControlNet Ä‘á»ƒ hiá»‡u suáº¥t tá»‘i Æ°u## Cháº¡y nhanh (Gradio UI)

```

- **âš¡ Auto-Detection**: Tá»± Ä‘á»™ng chá»n backend tá»‘t nháº¥t (GGUF hoáº·c Transformers)- Cháº¡y giao diá»‡n: `python apps/gradio_app.py`

## ğŸ“‹ Requirements

- **ğŸ”§ Adaptive VRAM**: Tá»± Ä‘á»™ng tá»‘i Æ°u theo VRAM cÃ³ sáºµn (4GB personal â†’ 10GB+ server)- Quy trÃ¬nh: Táº£i áº£nh siÃªu Ã¢m â†’ Nháº¥n â€œBáº¯t Ä‘áº§u xá»­ lÃ½â€ â†’ Táº£i áº£nh káº¿t quáº£.

- Python 3.8+

- For GPU: NVIDIA GPU with 4GB+ VRAM- **ğŸ¯ High Performance**: Tá»‘i Æ°u hÃ³a cho tá»‘c Ä‘á»™ vÃ  cháº¥t lÆ°á»£ng- áº¢nh káº¿t quáº£ máº·c Ä‘á»‹nh lÆ°u táº¡i: `outputs/gradio/`

- For CPU: 8GB+ RAM

- **ğŸ’» Cross-Platform**: Há»— trá»£ GPU CUDA, CPU, vÃ  cÃ¡c mÃ´i trÆ°á»ng hybrid

## ğŸ”§ Setup

## Xá»­ lÃ½ theo lÃ´ (Batch)

1. **Clone the repository:**

```bash## ğŸ“¦ CÃ i Ä‘áº·t nhanh- áº¢nh máº«u náº±m trong `samples/`

git clone <your-repo>

cd BabyVis- CÃ³ thá»ƒ chuáº©n bá»‹ danh sÃ¡ch áº£nh táº¡i `data/image_list.txt` (má»—i dÃ²ng 1 Ä‘Æ°á»ng dáº«n)

```

```bash- Cháº¡y: `python apps/batch_processor.py`

2. **Add ultrasound images:**

```bash# Clone repo- Káº¿t quáº£: `outputs/batch/`; Log: `logs/batch.log`

mkdir -p samples

# Copy your ultrasound images to samples/ foldergit clone https://github.com/VuThanhLam124/BabyVis.git

```

cd BabyVis## Cháº¡y trÃªn CPU (kháº¯c phá»¥c lá»—i CUDA/cuBLAS)

3. **Run with your preferred configuration:**

```bash- Náº¿u gáº·p lá»—i kiá»ƒu `libcublasLt.so.11`/`CUDA` hoáº·c chÆ°a cÃ i driver/phá»¥ thuá»™c CUDA Ä‘Ãºng báº£n:

# For 4GB GPU

./run_4gb.sh# Táº¡o conda environment  - Táº¡m thá»i Ã©p cháº¡y CPU: `CUDA_VISIBLE_DEVICES="" python apps/batch_processor.py` hoáº·c `FORCE_CPU=1 python apps/batch_processor.py`



# For 12GB GPU  conda create -n babyvis python=3.9 -y  - Code cÃ³ cÆ¡ cháº¿ tá»± fallback GPUâ†’CPU náº¿u lá»—i CUDA xáº£y ra trong lÃºc suy luáº­n.

./run_12gb.sh

conda activate babyvis

# For CPU only

./run_cpu.sh## Tuá»³ chá»n mÃ´ hÃ¬nh

```

# CÃ i Ä‘áº·t dependencies- Máº·c Ä‘á»‹nh SD v1.5 + ControlNet Canny (CPU náº¿u khÃ´ng cÃ³ GPU).

## ğŸ“ Project Structure

pip install -r requirements.txt- CÃ³ thá»ƒ Ä‘á»•i sang SDXL qua biáº¿n mÃ´i trÆ°á»ng hoáº·c override ID:

```

BabyVis/  - VÃ­ dá»¥ SDXL: 

â”œâ”€â”€ run_4gb.sh         # GPU 4GB configuration

â”œâ”€â”€ run_12gb.sh        # GPU 12GB configuration  # Cháº¡y ngay láº­p tá»©c    - `PREFER_SDXL=1 python apps/gradio_app.py`

â”œâ”€â”€ run_cpu.sh         # CPU configuration

â”œâ”€â”€ batch_processor.py # Main processing script./run_qwen_auto.sh    - Hoáº·c:

â”œâ”€â”€ model_downloader.py # Auto-download GGUF model

â”œâ”€â”€ samples/           # Input ultrasound images```      - `BASE_MODEL_ID="stabilityai/stable-diffusion-xl-base-1.0" \\

â”œâ”€â”€ outputs/           # Generated baby faces

â”œâ”€â”€ models/           # GGUF model storage (auto-created)         CONTROLNET_ID="diffusers/controlnet-canny-sdxl-1.0" \\

â””â”€â”€ src/babyvis/      # Core inference code

```## ğŸ® CÃ¡ch sá»­ dá»¥ng         python apps/gradio_app.py`



## ğŸ¤– Model Information- CÃ¡c tham sá»‘ gá»£i Ã½:



- **Model**: Qwen_Image_Edit-Q4_K_M.gguf (7.5GB)### Cháº¿ Ä‘á»™ tá»± Ä‘á»™ng (Khuyáº¿n nghá»‹)  - SD v1.5: steps 40â€“60, CFG 7â€“9, control 0.7â€“1.0

- **Source**: QuantStack/Qwen-Image-Edit-GGUF

- **Auto-download**: Model downloads automatically on first run```bash  - SDXL: steps 30â€“40, CFG 5â€“7, control 0.6â€“0.9



## âš™ï¸ Hardware Configurations./run_qwen_auto.sh    # Tá»± Ä‘á»™ng chá»n backend tá»‘t nháº¥t



| Configuration | GPU Layers | VRAM Usage | RAM Usage | Speed |```### DÃ¹ng Qwen Image Edit (Qwen/Qwen-Image-Edit)

|---------------|------------|------------|-----------|-------|

| 4GB GPU       | 20         | ~3.5GB     | ~4GB      | Fast  |- Báº­t dÃ¹ng Qwen Image Edit thay cho Stable Diffusion + ControlNet:

| 12GB GPU      | 35         | ~11GB      | ~2GB      | Fastest |

| CPU Only      | 0          | 0          | ~8GB      | Slower |### Cháº¿ Ä‘á»™ cá»¥ thá»ƒ  - `USE_QWEN_IMAGE_EDIT=1 python apps/gradio_app.py`



## ğŸ¯ Features```bash  - hoáº·c trong batch: `USE_QWEN_IMAGE_EDIT=1 python apps/batch_processor.py`



- âœ… Single GGUF model (simplified)./run_qwen_gguf.sh         # Force GGUF (tÆ°Æ¡ng thÃ­ch cao)- YÃªu cáº§u cÃ i thÃªm thÆ° viá»‡n: `transformers`, `accelerate`, `sentencepiece`, `safetensors` (Ä‘Ã£ thÃªm sáºµn trong `requirements.txt`).

- âœ… Auto-download from HuggingFace

- âœ… Hardware auto-detection./run_qwen_transformers.sh # Force Transformers (cháº¥t lÆ°á»£ng cao)- Ghi chÃº: MÃ£ táº£i Qwen dÃ¹ng `trust_remote_code=True` theo hÆ°á»›ng dáº«n tá»« Hugging Face. Äáº§u ra áº£nh Ä‘Æ°á»£c decode tá»± Ä‘á»™ng tá»« response cá»§a model.

- âœ… Batch processing

- âœ… 3 optimization profiles./run_qwen_cpu.sh          # CPU only (mÃ¡y yáº¿u)

- âœ… Simple configuration

```### DÃ¹ng báº£n nháº¹ GGUF (QuantStack/Qwen-Image-Edit-GGUF)

## ğŸ“Š Output

- Báº­t backend GGUF (cháº¡y báº±ng llama.cpp, phÃ¹ há»£p CPU/GPU VRAM ~4GB):

Generated baby faces will be saved in the `outputs/` directory with filenames like:

- `predicted_1.png`### Python API  - `USE_QWEN_GGUF=1 python apps/gradio_app.py`

- `predicted_2.png` 

- etc.```python  - hoáº·c `USE_QWEN_GGUF=1 python apps/batch_processor.py`



## ğŸ› ï¸ Troubleshootingfrom babyvis.inference import generate_predict_auto- Tuá»³ chá»n táº£i model:



### Model Download Issues  - DÃ¹ng file cá»¥c bá»™: Ä‘áº·t `QWEN_GGUF_PATH=/path/to/model.gguf`

```bash

python3 -c "# Táº¡o áº£nh dá»± Ä‘oÃ¡n  - Hoáº·c Ä‘á»ƒ tá»± táº£i tá»« HF: `QWEN_GGUF_REPO=QuantStack/Qwen-Image-Edit-GGUF` vÃ  (tuá»³ chá»n) `QWEN_GGUF_FILENAME=qwen-image-edit-q4_k_m.gguf`

from model_downloader import ModelDownloader

downloader = ModelDownloader()generate_predict_auto(- Tinh chá»‰nh hiá»‡u nÄƒng/thÃ´ng sá»‘ tháº¥p VRAM:

downloader.download_if_needed()

"    input_path="samples/ultrasound.jpg",  - `QWEN_N_GPU_LAYERS=12` (máº·c Ä‘á»‹nh, 4GB VRAM nÃªn Ä‘á»ƒ 8â€“16; Ä‘áº·t 0 Ä‘á»ƒ cháº¡y CPU-only)

```

    output_path="output/baby.png",  - `QWEN_N_THREADS=<sá»‘ luá»“ng CPU>`; `QWEN_N_CTX=2048`

### Memory Issues

- Use CPU mode if GPU memory is insufficient    backend="auto",  # hoáº·c "qwen", "qwen_gguf"- YÃªu cáº§u cÃ i `llama-cpp-python` (Ä‘Ã£ cÃ³ trong `requirements.txt`). Cáº§n báº£n llama.cpp há»— trá»£ multi-modal (VL). Náº¿u backend GGUF chá»‰ tráº£ vá» vÄƒn báº£n thay vÃ¬ áº£nh, code sáº½ tá»± Ä‘á»™ng dÃ¹ng vÄƒn báº£n Ä‘Ã³ lÃ m prompt tÄƒng cÆ°á»ng cho ControlNet Ä‘á»ƒ váº«n táº¡o Ä‘Æ°á»£c áº£nh.

- Close other applications to free RAM

- Try 4GB mode instead of 12GB mode    ethnicity="mixed ethnicity"



### CUDA Issues)## Cáº¥u trÃºc thÆ° má»¥c (Ä‘Ã£ cÆ¡ cáº¥u láº¡i)

```bash

# Check CUDA availability```- `src/babyvis/`: mÃ£ nguá»“n chÃ­nh (inference, model_utils)

python3 -c "

import subprocess- `apps/`: Ä‘iá»ƒm cháº¡y

try:

    result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)## ğŸ”§ Cáº¥u hÃ¬nh  - `gradio_app.py`: giao diá»‡n Gradio

    print(result.stdout)

except:  - `batch_processor.py`: xá»­ lÃ½ theo lÃ´

    print('CUDA not available, will use CPU')

"### Environment Variables- `web/`: giao diá»‡n web tÄ©nh (index.html, style.css, app.js) â€” Ä‘Ã£ loáº¡i bá» toÃ n bá»™ icon SVG

```

```bash- `outputs/`: áº£nh káº¿t quáº£ (`gradio/`, `batch/`, `tmp/`)

## ğŸ“ License

# Backend selection- `samples/`: áº£nh máº«u

See LICENSE file for details.

export QWEN_BACKEND=auto          # auto, qwen, qwen_gguf- `config/`: cáº¥u hÃ¬nh batch (`config/batch_config.json`)

## ğŸ¤ Contributing

export USE_QWEN_IMAGE_EDIT=1      # Force transformers- `data/`: dá»¯ liá»‡u vÃ o (vd. `data/image_list.txt`)

This is a simplified GGUF-only version focused on ease of use and performance.
export USE_QWEN_GGUF=1            # Force GGUF- `logs/`: log cháº¡y batch



# Performance tuningGhi chÃº: CÃ¡c script trong `apps/` tá»± thÃªm `src/` vÃ o `PYTHONPATH` khi cháº¡y trá»±c tiáº¿p, nÃªn khÃ´ng cáº§n cÃ i Ä‘áº·t gÃ³i.

export QWEN_4BIT=true             # 4-bit quantization

export QWEN_FLASH_ATTN=true       # Flash attention## Báº£o trÃ¬ vÃ  lÆ°u Ã½

export QWEN_N_GPU_LAYERS=20       # GPU layers for GGUF- Repo Ä‘Ã£ Ä‘Æ°á»£c dá»n dáº¹p vÃ  loáº¡i bá» táº¥t cáº£ icon (SVG/biá»ƒu tÆ°á»£ng) khá»i giao diá»‡n tÄ©nh.

- HÃ¬nh áº£nh sinh ra chá»‰ mang tÃ­nh tham kháº£o, khÃ´ng thay tháº¿ Ã½ kiáº¿n y khoa.

# Local models
export QWEN_LOCAL_PATH=/path/to/local/model
export QWEN_GGUF_PATH=/path/to/model.gguf
```

### Batch Processing
```python
from apps.batch_processor import BatchImageProcessor

processor = BatchImageProcessor()
results = processor.process_image_list([
    "samples/1.jpeg",
    "samples/2.png",
    "samples/3.jpg"
])
```

## ğŸ¯ Backends

| Backend | Æ¯u Ä‘iá»ƒm | NhÆ°á»£c Ä‘iá»ƒm | Khuyáº¿n nghá»‹ |
|---------|---------|------------|-------------|
| **Auto** | Tá»± Ä‘á»™ng chá»n tá»‘t nháº¥t | - | âœ… **Default** |
| **GGUF** | TÆ°Æ¡ng thÃ­ch cao, Ã­t VRAM | Cháº­m hÆ¡n | Personal PC |
| **Transformers** | Cháº¥t lÆ°á»£ng cao, nhanh | Nhiá»u VRAM | Server/GPU máº¡nh |
| **CPU** | KhÃ´ng cáº§n GPU | Ráº¥t cháº­m | Backup mode |

## ğŸ“Š Hiá»‡u suáº¥t

### VRAM Requirements
- **4GB**: GGUF Q4_K_M, 4-bit quantization
- **6GB**: GGUF Q5_K_M, optimal balance  
- **8GB+**: Transformers full precision
- **10GB+**: Flash attention enabled

### Tá»‘c Ä‘á»™ Æ°á»›c tÃ­nh
- **GGUF CPU**: ~60-120s/image
- **GGUF GPU**: ~15-30s/image  
- **Transformers GPU**: ~5-15s/image

## ğŸ” Troubleshooting

### Common Issues

**CUDA errors:**
```bash
export FORCE_CPU=1
./run_qwen_cpu.sh
```

**Out of memory:**
```bash
export QWEN_4BIT=true
export QWEN_8BIT=true
./run_qwen_gguf.sh
```

**Model not found:**
```bash
# Thá»­ cÃ¡c repo fallback
export QWEN_GGUF_REPO=bartowski/Qwen-Image-Edit-GGUF
./run_qwen_gguf.sh
```

## ğŸ“ Project Structure

```
BabyVis/
â”œâ”€â”€ src/babyvis/           # Core Qwen processing
â”‚   â”œâ”€â”€ model_utils.py     # Model loaders & VRAM detection
â”‚   â””â”€â”€ inference.py       # Image generation pipeline
â”œâ”€â”€ apps/                  # Applications
â”‚   â”œâ”€â”€ batch_processor.py # Batch processing
â”‚   â””â”€â”€ gradio_app.py      # Web interface
â”œâ”€â”€ samples/               # Sample images
â”œâ”€â”€ outputs/               # Generated results
â””â”€â”€ run_qwen_*.sh         # Execution scripts
```

## ğŸ¨ TÃ¹y chá»‰nh

### Custom Instructions
```python
generate_predict_qwen_only(
    input_path="input.jpg",
    output_path="output.png",
    instruction="Transform this ultrasound into a realistic Asian newborn baby photo"
)
```

### Quality Settings
```python
# High quality (server)
export QWEN_N_CTX=4096
export QWEN_FLASH_ATTN=true

# Balanced (personal)  
export QWEN_N_CTX=2048
export QWEN_4BIT=true

# Fast (minimal)
export QWEN_N_CTX=1024
export QWEN_N_GPU_LAYERS=8
```

## ğŸ¤ Contributing

1. Fork repository
2. Create feature branch: `git checkout -b feature/amazing-feature`
3. Commit changes: `git commit -m 'Add amazing feature'`
4. Push to branch: `git push origin feature/amazing-feature`
5. Open Pull Request

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file.

## ğŸ™ Acknowledgments

- **Qwen Team**: Qwen Image Edit model
- **llama.cpp**: GGUF inference engine
- **Hugging Face**: Model hosting & transformers
- **CUDA/PyTorch**: GPU acceleration

---

**ğŸš€ Ready to generate baby predictions with Qwen AI!**

For support: Create an issue or contact [@VuThanhLam124](https://github.com/VuThanhLam124)