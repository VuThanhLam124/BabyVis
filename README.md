# ğŸ¤– BabyVis - Qwen Edition# BabyVis â€” Táº¡o áº£nh em bÃ© tá»« áº£nh siÃªu Ã¢m



**Dá»± Ä‘oÃ¡n hÃ¬nh áº£nh em bÃ© tá»« siÃªu Ã¢m sá»­ dá»¥ng Qwen Image Edit AI**BabyVis lÃ  má»™t cÃ´ng cá»¥ táº¡o áº£nh em bÃ© tá»« áº£nh siÃªu Ã¢m dá»±a trÃªn Stable Diffusion + ControlNet (Canny), kÃ¨m giao diá»‡n Gradio thÃ¢n thiá»‡n vÃ  cháº¿ Ä‘á»™ xá»­ lÃ½ theo lÃ´.



[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://python.org)## CÃ i Ä‘áº·t

[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)- YÃªu cáº§u Python 3.9+

- CÃ i thÆ° viá»‡n:

## ğŸš€ TÃ­nh nÄƒng  - `pip install -r requirements.txt`



- **ğŸ§  Pure Qwen AI**: Sá»­ dá»¥ng hoÃ n toÃ n Qwen Image Edit - loáº¡i bá» ControlNet Ä‘á»ƒ hiá»‡u suáº¥t tá»‘i Æ°u## Cháº¡y nhanh (Gradio UI)

- **âš¡ Auto-Detection**: Tá»± Ä‘á»™ng chá»n backend tá»‘t nháº¥t (GGUF hoáº·c Transformers)- Cháº¡y giao diá»‡n: `python apps/gradio_app.py`

- **ğŸ”§ Adaptive VRAM**: Tá»± Ä‘á»™ng tá»‘i Æ°u theo VRAM cÃ³ sáºµn (4GB personal â†’ 10GB+ server)- Quy trÃ¬nh: Táº£i áº£nh siÃªu Ã¢m â†’ Nháº¥n â€œBáº¯t Ä‘áº§u xá»­ lÃ½â€ â†’ Táº£i áº£nh káº¿t quáº£.

- **ğŸ¯ High Performance**: Tá»‘i Æ°u hÃ³a cho tá»‘c Ä‘á»™ vÃ  cháº¥t lÆ°á»£ng- áº¢nh káº¿t quáº£ máº·c Ä‘á»‹nh lÆ°u táº¡i: `outputs/gradio/`

- **ğŸ’» Cross-Platform**: Há»— trá»£ GPU CUDA, CPU, vÃ  cÃ¡c mÃ´i trÆ°á»ng hybrid

## Xá»­ lÃ½ theo lÃ´ (Batch)

## ğŸ“¦ CÃ i Ä‘áº·t nhanh- áº¢nh máº«u náº±m trong `samples/`

- CÃ³ thá»ƒ chuáº©n bá»‹ danh sÃ¡ch áº£nh táº¡i `data/image_list.txt` (má»—i dÃ²ng 1 Ä‘Æ°á»ng dáº«n)

```bash- Cháº¡y: `python apps/batch_processor.py`

# Clone repo- Káº¿t quáº£: `outputs/batch/`; Log: `logs/batch.log`

git clone https://github.com/VuThanhLam124/BabyVis.git

cd BabyVis## Cháº¡y trÃªn CPU (kháº¯c phá»¥c lá»—i CUDA/cuBLAS)

- Náº¿u gáº·p lá»—i kiá»ƒu `libcublasLt.so.11`/`CUDA` hoáº·c chÆ°a cÃ i driver/phá»¥ thuá»™c CUDA Ä‘Ãºng báº£n:

# Táº¡o conda environment  - Táº¡m thá»i Ã©p cháº¡y CPU: `CUDA_VISIBLE_DEVICES="" python apps/batch_processor.py` hoáº·c `FORCE_CPU=1 python apps/batch_processor.py`

conda create -n babyvis python=3.9 -y  - Code cÃ³ cÆ¡ cháº¿ tá»± fallback GPUâ†’CPU náº¿u lá»—i CUDA xáº£y ra trong lÃºc suy luáº­n.

conda activate babyvis

## Tuá»³ chá»n mÃ´ hÃ¬nh

# CÃ i Ä‘áº·t dependencies- Máº·c Ä‘á»‹nh SD v1.5 + ControlNet Canny (CPU náº¿u khÃ´ng cÃ³ GPU).

pip install -r requirements.txt- CÃ³ thá»ƒ Ä‘á»•i sang SDXL qua biáº¿n mÃ´i trÆ°á»ng hoáº·c override ID:

  - VÃ­ dá»¥ SDXL: 

# Cháº¡y ngay láº­p tá»©c    - `PREFER_SDXL=1 python apps/gradio_app.py`

./run_qwen_auto.sh    - Hoáº·c:

```      - `BASE_MODEL_ID="stabilityai/stable-diffusion-xl-base-1.0" \\

         CONTROLNET_ID="diffusers/controlnet-canny-sdxl-1.0" \\

## ğŸ® CÃ¡ch sá»­ dá»¥ng         python apps/gradio_app.py`

- CÃ¡c tham sá»‘ gá»£i Ã½:

### Cháº¿ Ä‘á»™ tá»± Ä‘á»™ng (Khuyáº¿n nghá»‹)  - SD v1.5: steps 40â€“60, CFG 7â€“9, control 0.7â€“1.0

```bash  - SDXL: steps 30â€“40, CFG 5â€“7, control 0.6â€“0.9

./run_qwen_auto.sh    # Tá»± Ä‘á»™ng chá»n backend tá»‘t nháº¥t

```### DÃ¹ng Qwen Image Edit (Qwen/Qwen-Image-Edit)

- Báº­t dÃ¹ng Qwen Image Edit thay cho Stable Diffusion + ControlNet:

### Cháº¿ Ä‘á»™ cá»¥ thá»ƒ  - `USE_QWEN_IMAGE_EDIT=1 python apps/gradio_app.py`

```bash  - hoáº·c trong batch: `USE_QWEN_IMAGE_EDIT=1 python apps/batch_processor.py`

./run_qwen_gguf.sh         # Force GGUF (tÆ°Æ¡ng thÃ­ch cao)- YÃªu cáº§u cÃ i thÃªm thÆ° viá»‡n: `transformers`, `accelerate`, `sentencepiece`, `safetensors` (Ä‘Ã£ thÃªm sáºµn trong `requirements.txt`).

./run_qwen_transformers.sh # Force Transformers (cháº¥t lÆ°á»£ng cao)- Ghi chÃº: MÃ£ táº£i Qwen dÃ¹ng `trust_remote_code=True` theo hÆ°á»›ng dáº«n tá»« Hugging Face. Äáº§u ra áº£nh Ä‘Æ°á»£c decode tá»± Ä‘á»™ng tá»« response cá»§a model.

./run_qwen_cpu.sh          # CPU only (mÃ¡y yáº¿u)

```### DÃ¹ng báº£n nháº¹ GGUF (QuantStack/Qwen-Image-Edit-GGUF)

- Báº­t backend GGUF (cháº¡y báº±ng llama.cpp, phÃ¹ há»£p CPU/GPU VRAM ~4GB):

### Python API  - `USE_QWEN_GGUF=1 python apps/gradio_app.py`

```python  - hoáº·c `USE_QWEN_GGUF=1 python apps/batch_processor.py`

from babyvis.inference import generate_predict_auto- Tuá»³ chá»n táº£i model:

  - DÃ¹ng file cá»¥c bá»™: Ä‘áº·t `QWEN_GGUF_PATH=/path/to/model.gguf`

# Táº¡o áº£nh dá»± Ä‘oÃ¡n  - Hoáº·c Ä‘á»ƒ tá»± táº£i tá»« HF: `QWEN_GGUF_REPO=QuantStack/Qwen-Image-Edit-GGUF` vÃ  (tuá»³ chá»n) `QWEN_GGUF_FILENAME=qwen-image-edit-q4_k_m.gguf`

generate_predict_auto(- Tinh chá»‰nh hiá»‡u nÄƒng/thÃ´ng sá»‘ tháº¥p VRAM:

    input_path="samples/ultrasound.jpg",  - `QWEN_N_GPU_LAYERS=12` (máº·c Ä‘á»‹nh, 4GB VRAM nÃªn Ä‘á»ƒ 8â€“16; Ä‘áº·t 0 Ä‘á»ƒ cháº¡y CPU-only)

    output_path="output/baby.png",  - `QWEN_N_THREADS=<sá»‘ luá»“ng CPU>`; `QWEN_N_CTX=2048`

    backend="auto",  # hoáº·c "qwen", "qwen_gguf"- YÃªu cáº§u cÃ i `llama-cpp-python` (Ä‘Ã£ cÃ³ trong `requirements.txt`). Cáº§n báº£n llama.cpp há»— trá»£ multi-modal (VL). Náº¿u backend GGUF chá»‰ tráº£ vá» vÄƒn báº£n thay vÃ¬ áº£nh, code sáº½ tá»± Ä‘á»™ng dÃ¹ng vÄƒn báº£n Ä‘Ã³ lÃ m prompt tÄƒng cÆ°á»ng cho ControlNet Ä‘á»ƒ váº«n táº¡o Ä‘Æ°á»£c áº£nh.

    ethnicity="mixed ethnicity"

)## Cáº¥u trÃºc thÆ° má»¥c (Ä‘Ã£ cÆ¡ cáº¥u láº¡i)

```- `src/babyvis/`: mÃ£ nguá»“n chÃ­nh (inference, model_utils)

- `apps/`: Ä‘iá»ƒm cháº¡y

## ğŸ”§ Cáº¥u hÃ¬nh  - `gradio_app.py`: giao diá»‡n Gradio

  - `batch_processor.py`: xá»­ lÃ½ theo lÃ´

### Environment Variables- `web/`: giao diá»‡n web tÄ©nh (index.html, style.css, app.js) â€” Ä‘Ã£ loáº¡i bá» toÃ n bá»™ icon SVG

```bash- `outputs/`: áº£nh káº¿t quáº£ (`gradio/`, `batch/`, `tmp/`)

# Backend selection- `samples/`: áº£nh máº«u

export QWEN_BACKEND=auto          # auto, qwen, qwen_gguf- `config/`: cáº¥u hÃ¬nh batch (`config/batch_config.json`)

export USE_QWEN_IMAGE_EDIT=1      # Force transformers- `data/`: dá»¯ liá»‡u vÃ o (vd. `data/image_list.txt`)

export USE_QWEN_GGUF=1            # Force GGUF- `logs/`: log cháº¡y batch



# Performance tuningGhi chÃº: CÃ¡c script trong `apps/` tá»± thÃªm `src/` vÃ o `PYTHONPATH` khi cháº¡y trá»±c tiáº¿p, nÃªn khÃ´ng cáº§n cÃ i Ä‘áº·t gÃ³i.

export QWEN_4BIT=true             # 4-bit quantization

export QWEN_FLASH_ATTN=true       # Flash attention## Báº£o trÃ¬ vÃ  lÆ°u Ã½

export QWEN_N_GPU_LAYERS=20       # GPU layers for GGUF- Repo Ä‘Ã£ Ä‘Æ°á»£c dá»n dáº¹p vÃ  loáº¡i bá» táº¥t cáº£ icon (SVG/biá»ƒu tÆ°á»£ng) khá»i giao diá»‡n tÄ©nh.

- HÃ¬nh áº£nh sinh ra chá»‰ mang tÃ­nh tham kháº£o, khÃ´ng thay tháº¿ Ã½ kiáº¿n y khoa.

# Local models
export QWEN_LOCAL_PATH=/path/to/local/model
export QWEN_GGUF_PATH=/path/to/model.gguf
```

### Batch Processing
```python
from apps.batch_processor import BatchImageProcessor

processor = BatchImageProcessor()
results = processor.process_image_list([
    "samples/1.jpeg",
    "samples/2.png",
    "samples/3.jpg"
])
```

## ğŸ¯ Backends

| Backend | Æ¯u Ä‘iá»ƒm | NhÆ°á»£c Ä‘iá»ƒm | Khuyáº¿n nghá»‹ |
|---------|---------|------------|-------------|
| **Auto** | Tá»± Ä‘á»™ng chá»n tá»‘t nháº¥t | - | âœ… **Default** |
| **GGUF** | TÆ°Æ¡ng thÃ­ch cao, Ã­t VRAM | Cháº­m hÆ¡n | Personal PC |
| **Transformers** | Cháº¥t lÆ°á»£ng cao, nhanh | Nhiá»u VRAM | Server/GPU máº¡nh |
| **CPU** | KhÃ´ng cáº§n GPU | Ráº¥t cháº­m | Backup mode |

## ğŸ“Š Hiá»‡u suáº¥t

### VRAM Requirements
- **4GB**: GGUF Q4_K_M, 4-bit quantization
- **6GB**: GGUF Q5_K_M, optimal balance  
- **8GB+**: Transformers full precision
- **10GB+**: Flash attention enabled

### Tá»‘c Ä‘á»™ Æ°á»›c tÃ­nh
- **GGUF CPU**: ~60-120s/image
- **GGUF GPU**: ~15-30s/image  
- **Transformers GPU**: ~5-15s/image

## ğŸ” Troubleshooting

### Common Issues

**CUDA errors:**
```bash
export FORCE_CPU=1
./run_qwen_cpu.sh
```

**Out of memory:**
```bash
export QWEN_4BIT=true
export QWEN_8BIT=true
./run_qwen_gguf.sh
```

**Model not found:**
```bash
# Thá»­ cÃ¡c repo fallback
export QWEN_GGUF_REPO=bartowski/Qwen-Image-Edit-GGUF
./run_qwen_gguf.sh
```

## ğŸ“ Project Structure

```
BabyVis/
â”œâ”€â”€ src/babyvis/           # Core Qwen processing
â”‚   â”œâ”€â”€ model_utils.py     # Model loaders & VRAM detection
â”‚   â””â”€â”€ inference.py       # Image generation pipeline
â”œâ”€â”€ apps/                  # Applications
â”‚   â”œâ”€â”€ batch_processor.py # Batch processing
â”‚   â””â”€â”€ gradio_app.py      # Web interface
â”œâ”€â”€ samples/               # Sample images
â”œâ”€â”€ outputs/               # Generated results
â””â”€â”€ run_qwen_*.sh         # Execution scripts
```

## ğŸ¨ TÃ¹y chá»‰nh

### Custom Instructions
```python
generate_predict_qwen_only(
    input_path="input.jpg",
    output_path="output.png",
    instruction="Transform this ultrasound into a realistic Asian newborn baby photo"
)
```

### Quality Settings
```python
# High quality (server)
export QWEN_N_CTX=4096
export QWEN_FLASH_ATTN=true

# Balanced (personal)  
export QWEN_N_CTX=2048
export QWEN_4BIT=true

# Fast (minimal)
export QWEN_N_CTX=1024
export QWEN_N_GPU_LAYERS=8
```

## ğŸ¤ Contributing

1. Fork repository
2. Create feature branch: `git checkout -b feature/amazing-feature`
3. Commit changes: `git commit -m 'Add amazing feature'`
4. Push to branch: `git push origin feature/amazing-feature`
5. Open Pull Request

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file.

## ğŸ™ Acknowledgments

- **Qwen Team**: Qwen Image Edit model
- **llama.cpp**: GGUF inference engine
- **Hugging Face**: Model hosting & transformers
- **CUDA/PyTorch**: GPU acceleration

---

**ğŸš€ Ready to generate baby predictions with Qwen AI!**

For support: Create an issue or contact [@VuThanhLam124](https://github.com/VuThanhLam124)